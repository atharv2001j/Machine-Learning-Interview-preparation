{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d63ab660",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center;\">Machine Learning</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b41b7fb",
   "metadata": {},
   "source": [
    "<h2>Classification Algorithm in Machine Learning </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d719b872",
   "metadata": {},
   "source": [
    "As we know, the Supervised Machine Learning algorithm can be broadly classified into Regression and Classification Algorithms. In Regression algorithms, we have predicted the output for continuous values, but to predict the categorical values, we need Classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9f9662",
   "metadata": {},
   "source": [
    "<h3> What is the Classification Algorithm?</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed7bc8b",
   "metadata": {},
   "source": [
    "\n",
    "1. **Supervised Learning**: Classification is a type of supervised learning, which means it requires labeled input data, where each data point is associated with its corresponding category or class.\n",
    "\n",
    "\n",
    "2. **Categorical Output**: In classification, the output variable is categorical, not continuous. This means that the algorithm assigns data points to specific classes or categories, such as \"Spam\" or \"Not Spam,\" \"Yes\" or \"No,\" \"Dog\" or \"Cat.\"\n",
    "\n",
    "\n",
    "3. **Binary and Multi-class Classification**: There are two main types of classification problems:\n",
    "   - **Binary Classification**: In binary classification, there are only two possible outcomes or classes. Examples include gender prediction (Male or Female), email spam detection (Spam or Not Spam), and more.\n",
    "   \n",
    "   - **Multi-class Classification**: In multi-class classification, there are more than two possible outcomes or classes. Examples include classifying types of crops, types of music, or any problem with multiple distinct categories.\n",
    "\n",
    "\n",
    "4. **Classifier**: The algorithm that performs classification is called a classifier. Different machine learning algorithms can be used as classifiers, such as decision trees, support vector machines, logistic regression, random forests, and more.\n",
    "\n",
    "\n",
    "Classification algorithms can be better understood using the below diagram. In the below diagram, there are two classes, class A and Class B. These classes have features that are similar to each other and dissimilar to other classes.\n",
    "\n",
    "<img src='class.png'>\n",
    "\n",
    "5. **Examples**: Email Spam Detection is indeed a common example of binary classification. For multi-class classification, you could think of applications like image classification (identifying objects in images), sentiment analysis (categorizing text as positive, negative, or neutral), and species identification (classifying animals or plants into different species).\n",
    "\n",
    "\n",
    "Classification is a fundamental machine learning task with numerous real-world applications, including medical diagnosis, document categorization, fraud detection, and more. It's an important technique for automating decision-making processes based on historical data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6568837",
   "metadata": {},
   "source": [
    "<h3>Learners in Classification Problems:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007f05ae",
   "metadata": {},
   "source": [
    "\n",
    "1. **Lazy Learners (Instance-Based Learning)**:\n",
    "   - Lazy learners do not build a model during the training phase. Instead, they store the entire training dataset and make predictions only when given a test instance.\n",
    "   - These algorithms essentially memorize the training data and use it to make predictions by finding the most similar instances in the training set.\n",
    "   - Lazy learners have low training time but higher prediction time, as they need to compare the test instance to all stored training instances to make a prediction.\n",
    "   - Example algorithms: k-Nearest Neighbors (K-NN) and Case-Based Reasoning.\n",
    "\n",
    "\n",
    "2. **Eager Learners (Model-Based Learning)**:\n",
    "   - Eager learners, also known as eager learners, build a classification model during the training phase based on the provided training data.\n",
    "   - This model is then used to make predictions on new, unseen data points quickly.\n",
    "   - Eager learners have higher training time because they create a model, but prediction time is usually faster than lazy learners.\n",
    "   - Example algorithms: Decision Trees, Naïve Bayes, Artificial Neural Networks (ANN).\n",
    "\n",
    "\n",
    "Here are a few additional points to consider:\n",
    "\n",
    "- Lazy learners can be advantageous when you have a large and diverse training dataset because they can adapt well to various data distributions. However, they might be slower in making predictions.\n",
    "\n",
    "\n",
    "- Eager learners are preferred when you have a reasonably sized training dataset and you want to make predictions quickly once the model is trained.\n",
    "\n",
    "\n",
    "- The choice between lazy and eager learners depends on the specific problem, available computational resources, and the nature of the data.\n",
    "\n",
    "\n",
    "Both types of learners have their strengths and weaknesses, and the selection of the appropriate algorithm depends on the specific requirements and constraints of the task at hand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "700e213b",
   "metadata": {},
   "source": [
    "<h3>Types of ML Classification Algorithms:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab35414a",
   "metadata": {},
   "source": [
    "Classification Algorithms can be further divided into the Mainly two category:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b39743",
   "metadata": {},
   "source": [
    "1) Linear Models\n",
    "\n",
    "    a. Logistic Regression\n",
    "    b. Support Vector Machines\n",
    "\n",
    "\n",
    "2) Non-linear Models\n",
    "\n",
    "    a. K-Nearest Neighbours\n",
    "    b. Kernel SVM\n",
    "    c. Naïve Bayes\n",
    "    d. Decision Tree Classification\n",
    "    e. Random Forest Classification\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe11d96",
   "metadata": {},
   "source": [
    "<h3> Evaluating a Classification model:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838535d",
   "metadata": {},
   "source": [
    "Once our model is completed, it is necessary to evaluate its performance; either it is a Classification or Regression model. So for evaluating a Classification model, we have the following ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b28889",
   "metadata": {},
   "source": [
    "\n",
    "1. **Log Loss or Cross-Entropy Loss**:\n",
    "   - Log loss, or cross-entropy loss, is a common metric used to evaluate classification models, especially when the model outputs probability values between 0 and 1.\n",
    "   - Log loss quantifies the accuracy of the model's predicted probabilities by measuring the similarity between the predicted probabilities and the actual class labels.\n",
    "   - For binary classification, the formula you provided calculates log loss. The goal is to minimize log loss, so a lower value indicates a better model.\n",
    "\n",
    "\n",
    "2. **Confusion Matrix**:\n",
    "   - The confusion matrix is a table that provides a comprehensive summary of a classification model's performance.\n",
    "   - It breaks down the model's predictions into four categories: true positives (correctly predicted positives), false positives (incorrectly predicted positives), true negatives (correctly predicted negatives), and false negatives (incorrectly predicted negatives).\n",
    "   - The confusion matrix allows you to calculate various performance metrics, such as accuracy, precision, recall, and F1 score.\n",
    "\n",
    "\n",
    "3. **AUC-ROC Curve**:\n",
    "   - The Receiver Operating Characteristic (ROC) curve and the Area Under the Curve (AUC) are commonly used to assess a classification model's performance across different classification thresholds.\n",
    "   - The ROC curve plots the true positive rate (TPR or sensitivity) against the false positive rate (FPR or 1-specificity) for various threshold values.\n",
    "   - AUC measures the area under the ROC curve, with a higher AUC indicating a better model. An AUC of 0.5 represents a random classifier, while an AUC of 1 represents a perfect classifier.\n",
    "\n",
    "\n",
    "In addition to these metrics, there are other evaluation measures you can use for classification models, such as precision, recall, F1 score, and specificity, depending on the specific requirements of your application and the balance between false positives and false negatives.\n",
    "\n",
    "The choice of evaluation metric depends on the nature of the problem and what aspect of model performance is most important. For instance, in medical diagnoses, where false negatives can be critical, you may prioritize recall, while in spam email detection, you may focus on precision to minimize false positives."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a461b94",
   "metadata": {},
   "source": [
    "<h3> Use cases of Classification Algorithms:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c1618",
   "metadata": {},
   "source": [
    "Classification algorithms can be used in different places. Below are some popular use cases of Classification Algorithms:\n",
    "\n",
    "1. Email Spam Detection\n",
    "2. Speech Recognition\n",
    "3. Identifications of Cancer tumor cells.\n",
    "4. Drugs Classification\n",
    "5. Biometric Identification, etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
