{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f73823f",
   "metadata": {},
   "source": [
    "<h3> 1. Overfitting </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9aba803",
   "metadata": {},
   "source": [
    "Overfitting occurs when our machine learning model tries to cover all the data points or more than the required data points present in the given dataset. Because of this, the model starts caching noise and inaccurate values present in the dataset, and all these factors reduce the efficiency and accuracy of the model. The overfitted model has low bias and high variance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37136226",
   "metadata": {},
   "source": [
    "<img src='overfit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9a3fa",
   "metadata": {},
   "source": [
    "- To avoid the overfitting use following methods:\n",
    "    1. Cross-Validation\n",
    "    2. Training with more data\n",
    "    3. Removing features\n",
    "    4. Early stopping the training\n",
    "    5. Regularization\n",
    "    6. Ensembling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0ece03",
   "metadata": {},
   "source": [
    "<h3> 2. Underfitting </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb97cfa4",
   "metadata": {},
   "source": [
    "Underfitting occurs when our machine learning model is not able to capture the underlying trend of the data. To avoid the overfitting in the model, the fed of training data can be stopped at an early stage, due to which the model may not learn enough from the training data. As a result, it may fail to find the best fit of the dominant trend in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d69005",
   "metadata": {},
   "source": [
    "<img src='underfit.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd87bcf",
   "metadata": {},
   "source": [
    "- To avoide the Underfitting problem:\n",
    "    1. Increase the training time of the model\n",
    "    2. Increase the number of features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b798ea",
   "metadata": {},
   "source": [
    "<h3> What is P-value? </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c16c1c",
   "metadata": {},
   "source": [
    "- In Statistical hypothesis testing, the P-value or sometimes called probability value, is used to observe the test results or more extreme results by assuming that the null hypothesis (H0) is true. \n",
    "\n",
    "- The p-value of 0.05 is known as the level of significance (Î±). Usually, it is considered using two suggestions, which are given below:\n",
    "1. If p-value>0.05: The large p-value shows that the null hypothesis needs to be accepted.\n",
    "2. If p-value<0.05: The small p-value shows that the null hypothesis needs to be rejected, and the result is declared as statically significant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "377b7ec3",
   "metadata": {},
   "source": [
    "<h3> Regularization in Machine Learning </h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3646db9c",
   "metadata": {},
   "source": [
    "- Regularization is one of the most important concepts of machine learning. It is a technique to prevent the model from overfitting by adding extra information to it.\n",
    "- Sometimes the machine learning model performs well with the training data but does not perform well with the test data. It means the model is not able to predict the output when deals with unseen data by introducing noise in the output, and hence the model is called overfitted. This problem can be deal with the help of a regularization technique.\n",
    "- **In regularization technique, we reduce the magnitude of the features by keeping the same number of features.**\n",
    "- There are two techniques for the regularization :\n",
    "    1. Lasso Regression (L1 Regularization )\n",
    "    2. Ridge Regression (L2 Regularization )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cef7ba",
   "metadata": {},
   "source": [
    "<h3> Encoding Techniques : </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abaa2e5",
   "metadata": {},
   "source": [
    "- The process of conversion of data from one form to another form is known as Encoding. It is used to transform the data so that data can be supported and used by different systems. \n",
    "- Encoding works similarly to converting temperature from centigrade to Fahrenheit, as it just gets converted in another form, but the original value always remains the same.\n",
    "- It has mainly two types:\n",
    "    1. Character Encoding\n",
    "    2. Image ,Audio and Video Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafe39a3",
   "metadata": {},
   "source": [
    "<h3> Feature Selection in ML</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6118cff3",
   "metadata": {},
   "source": [
    "- Feature selection is a way of selecting the subset of the most relevant features from the original features set by removing the redundant, irrelevant, or noisy features.\n",
    "- While developing the machine learning model, only a few variables in the dataset are useful for building the model, and the rest features are either redundant or irrelevant. If we input the dataset with all these redundant and irrelevant features, it may negatively impact and reduce the overall performance and accuracy of the model. Hence it is very important to identify and select the most appropriate features from the data and remove the irrelevant or less important features, which is done with the help of feature selection in machine learning.\n",
    "- There are mainly three methods for the feature selection:\n",
    "    1. Rapper\n",
    "    2. Filter\n",
    "    3. Embedded\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96914d",
   "metadata": {},
   "source": [
    "<h3>Bias and Variance</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d030c833",
   "metadata": {},
   "source": [
    "**Bias:** While making predictions, a difference occurs between prediction values made by the model and actual values/expected values, and this difference is known as bias errors or Errors due to bias.\n",
    "\n",
    "**Variance:** variance tells that how much a random variable is different from its expected value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e04142",
   "metadata": {},
   "source": [
    "<h3>Gradient Descent</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159f5547",
   "metadata": {},
   "source": [
    "- Gradient Descent is defined as one of the most commonly used iterative optimization algorithms of machine learning to train the machine learning and deep learning models. It helps in finding the local minimum of a function.\n",
    "- If we move towards a negative gradient or away from the gradient of the function at the current point, it will give the **local minimum** of that function.\n",
    "- Whenever we move towards a positive gradient or towards the gradient of the function at the current point, we will get the **local maximum** of that function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1899db30",
   "metadata": {},
   "source": [
    "<h3> Cost Function </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a3049d",
   "metadata": {},
   "source": [
    "- The cost function is defined as the measurement of difference or error between actual values and expected values at the current position and present in the form of a single real number.\n",
    "- It helps to increase and improve machine learning efficiency by providing feedback to this model so that it can minimize error and find the local or global minimum.\n",
    "- The slight difference between the loss function and the cost function is about the error within the training of machine learning models, as loss function refers to the error of one training example, while a cost function calculates the average error across an entire training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9924f3e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
