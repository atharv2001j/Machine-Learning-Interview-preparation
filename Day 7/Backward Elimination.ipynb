{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30073269",
   "metadata": {},
   "source": [
    "# <h1 style=\"text-align:center;\">Machine Learning</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aeab802",
   "metadata": {},
   "source": [
    "<h2> Backward Elimination </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61f54a8",
   "metadata": {},
   "source": [
    "\n",
    "**Background:**\n",
    "- Backward elimination is a feature selection technique used when building a machine learning model. Its goal is to remove features that do not significantly affect the prediction of the output (dependent variable).\n",
    "\n",
    "\n",
    "**Methods for Building a Model in Machine Learning:**\n",
    "- There are various methods to build a machine learning model, such as:\n",
    "  1. All-in\n",
    "  2. Backward Elimination\n",
    "  3. Forward Selection\n",
    "  4. Bidirectional Elimination\n",
    "  5. Score Comparison\n",
    "- In this explanation, we will focus on the Backward Elimination method.\n",
    "\n",
    "\n",
    "**Steps of Backward Elimination:**\n",
    "1. **Select a Significance Level (SL):** Choose a significance level (usually 0.05) that determines which features should stay in the model.\n",
    "\n",
    "2. **Fit the Complete Model:** Initially, create a model with all available predictors (independent variables).\n",
    "\n",
    "3. **Check P-values:** Calculate the P-value for each predictor. The P-value measures the significance of a variable's impact on the dependent variable.\n",
    "\n",
    "4. **Select the Predictor:** Identify the predictor with the highest P-value.\n",
    "   - If the P-value of this predictor is greater than the chosen significance level (SL), proceed to the next step.\n",
    "   - If the P-value is less than or equal to SL, you can finish the process, and your model is ready.\n",
    "\n",
    "\n",
    "**Remove Non-Significant Predictor:**\n",
    "5. **Remove the Predictor:** If the P-value of the selected predictor in step 4 is greater than the significance level (SL), remove this predictor from the model.\n",
    "\n",
    "6. **Rebuild the Model:** Create a new model with the remaining variables after removing the non-significant predictor.\n",
    "\n",
    "\n",
    "**Need for Backward Elimination:**\n",
    "- The goal of backward elimination is to create an optimal Multiple Linear Regression (MLR) model. In MLR, you typically have several independent variables and one dependent variable. However, it's essential to identify which independent variables have the most significant impact on the prediction and which ones have the least.\n",
    "\n",
    "\n",
    "**Why Backward Elimination:**\n",
    "- Including unnecessary features in the model can make it overly complex and may lead to poorer performance. Therefore, backward elimination helps streamline the model, including only the most significant features, simplifying the model, and improving its predictive performance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f16d489",
   "metadata": {},
   "source": [
    "<h3> Steps for Backward Elimination method:</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2aa09b",
   "metadata": {},
   "source": [
    "We will use the same model which we build in the previous chapter of MLR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "330b6cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.9501847627493607\n",
      "Test Score:  0.9347068473282966\n"
     ]
    }
   ],
   "source": [
    "# importing libraries  \n",
    "import numpy as nm  \n",
    "import matplotlib.pyplot as mtp  \n",
    "import pandas as pd  \n",
    "  \n",
    "#importing datasets  \n",
    "data_set= pd.read_csv('50_Startups.csv')  \n",
    "  \n",
    "#Extracting Independent and dependent Variable  \n",
    "x= data_set.iloc[:, :-1].values  \n",
    "y= data_set.iloc[:, 4].values  \n",
    "  \n",
    "#Catgorical data  \n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "# Assuming you have your data in the variable 'x' where the 4th column is categorical\n",
    "# Create a ColumnTransformer to apply transformations to specific columns\n",
    "column_transformer = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('onehot', OneHotEncoder(), [3])  # Apply OneHotEncoder to the 4th column\n",
    "    ],\n",
    "    remainder='passthrough'  # Keep the other columns as they are\n",
    ")\n",
    "\n",
    "# Apply the transformations to your data\n",
    "x = column_transformer.fit_transform(x) \n",
    "  \n",
    "#Avoiding the dummy variable trap:  \n",
    "x = x[:, 1:]  \n",
    "  \n",
    "  \n",
    "# Splitting the dataset into training and test set.  \n",
    "from sklearn.model_selection import train_test_split  \n",
    "x_train, x_test, y_train, y_test= train_test_split(x, y, test_size= 0.2, random_state=0)  \n",
    "  \n",
    "#Fitting the MLR model to the training set:  \n",
    "from sklearn.linear_model import LinearRegression  \n",
    "regressor= LinearRegression()  \n",
    "regressor.fit(x_train, y_train)  \n",
    "  \n",
    "#Predicting the Test set result;  \n",
    "y_pred= regressor.predict(x_test)  \n",
    "  \n",
    "#Checking the score  \n",
    "print('Train Score: ', regressor.score(x_train, y_train))  \n",
    "print('Test Score: ', regressor.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1009ea",
   "metadata": {},
   "source": [
    "The difference between both scores is 0.0154."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b837323",
   "metadata": {},
   "source": [
    "<h4>Step: 1- Preparation of Backward Elimination:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee6673d9",
   "metadata": {},
   "source": [
    "Importing the library: Firstly, we need to import the statsmodels.formula.api library, which is used for the estimation of various statistical models such as OLS(Ordinary Least Square). \n",
    "\n",
    "The OLS method can be mathematically represented as minimizing the sum of the squared residuals:\n",
    "\n",
    "   <h3> OLS= sum((actual-predicted)^2)</h3>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f75eea20",
   "metadata": {},
   "source": [
    "Importing the library: Firstly, we need to import the statsmodels.formula.api library, which is used for the estimation of various statistical models such as OLS(Ordinary Least Square). Below is the code for it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca2c33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as smf  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cdb447",
   "metadata": {},
   "source": [
    "Adding a column in matrix of features: As we can check in our MLR equation (a), there is one constant term b0, but this term is not present in our matrix of features, so we need to add it manually. We will add a column having values x0 = 1 associated with the constant term b0.\n",
    "To add this, we will use append function of Numpy library (nm which we have already imported into our code), and will assign a value of 1. Below is the code for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71e5f8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as nm\n",
    "x=nm.append(arr=nm.ones((50,1)).astype(int),values=x,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53d9008c",
   "metadata": {},
   "source": [
    "Here we have used axis =1, as we wanted to add a column. For adding a row, we can use axis =0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6bf968",
   "metadata": {},
   "source": [
    "Output: By executing the above line of code, a new column will be added into our matrix of features, which will have all values equal to 1. We can check it by clicking on the x dataset under the variable explorer option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d4a81a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0.0, 1.0, 165349.2, 136897.8, 471784.1],\n",
       "       [1, 0.0, 0.0, 162597.7, 151377.59, 443898.53],\n",
       "       [1, 1.0, 0.0, 153441.51, 101145.55, 407934.54],\n",
       "       [1, 0.0, 1.0, 144372.41, 118671.85, 383199.62],\n",
       "       [1, 1.0, 0.0, 142107.34, 91391.77, 366168.42],\n",
       "       [1, 0.0, 1.0, 131876.9, 99814.71, 362861.36],\n",
       "       [1, 0.0, 0.0, 134615.46, 147198.87, 127716.82],\n",
       "       [1, 1.0, 0.0, 130298.13, 145530.06, 323876.68],\n",
       "       [1, 0.0, 1.0, 120542.52, 148718.95, 311613.29],\n",
       "       [1, 0.0, 0.0, 123334.88, 108679.17, 304981.62],\n",
       "       [1, 1.0, 0.0, 101913.08, 110594.11, 229160.95],\n",
       "       [1, 0.0, 0.0, 100671.96, 91790.61, 249744.55],\n",
       "       [1, 1.0, 0.0, 93863.75, 127320.38, 249839.44],\n",
       "       [1, 0.0, 0.0, 91992.39, 135495.07, 252664.93],\n",
       "       [1, 1.0, 0.0, 119943.24, 156547.42, 256512.92],\n",
       "       [1, 0.0, 1.0, 114523.61, 122616.84, 261776.23],\n",
       "       [1, 0.0, 0.0, 78013.11, 121597.55, 264346.06],\n",
       "       [1, 0.0, 1.0, 94657.16, 145077.58, 282574.31],\n",
       "       [1, 1.0, 0.0, 91749.16, 114175.79, 294919.57],\n",
       "       [1, 0.0, 1.0, 86419.7, 153514.11, 0.0],\n",
       "       [1, 0.0, 0.0, 76253.86, 113867.3, 298664.47],\n",
       "       [1, 0.0, 1.0, 78389.47, 153773.43, 299737.29],\n",
       "       [1, 1.0, 0.0, 73994.56, 122782.75, 303319.26],\n",
       "       [1, 1.0, 0.0, 67532.53, 105751.03, 304768.73],\n",
       "       [1, 0.0, 1.0, 77044.01, 99281.34, 140574.81],\n",
       "       [1, 0.0, 0.0, 64664.71, 139553.16, 137962.62],\n",
       "       [1, 1.0, 0.0, 75328.87, 144135.98, 134050.07],\n",
       "       [1, 0.0, 1.0, 72107.6, 127864.55, 353183.81],\n",
       "       [1, 1.0, 0.0, 66051.52, 182645.56, 118148.2],\n",
       "       [1, 0.0, 1.0, 65605.48, 153032.06, 107138.38],\n",
       "       [1, 1.0, 0.0, 61994.48, 115641.28, 91131.24],\n",
       "       [1, 0.0, 1.0, 61136.38, 152701.92, 88218.23],\n",
       "       [1, 0.0, 0.0, 63408.86, 129219.61, 46085.25],\n",
       "       [1, 1.0, 0.0, 55493.95, 103057.49, 214634.81],\n",
       "       [1, 0.0, 0.0, 46426.07, 157693.92, 210797.67],\n",
       "       [1, 0.0, 1.0, 46014.02, 85047.44, 205517.64],\n",
       "       [1, 1.0, 0.0, 28663.76, 127056.21, 201126.82],\n",
       "       [1, 0.0, 0.0, 44069.95, 51283.14, 197029.42],\n",
       "       [1, 0.0, 1.0, 20229.59, 65947.93, 185265.1],\n",
       "       [1, 0.0, 0.0, 38558.51, 82982.09, 174999.3],\n",
       "       [1, 0.0, 0.0, 28754.33, 118546.05, 172795.67],\n",
       "       [1, 1.0, 0.0, 27892.92, 84710.77, 164470.71],\n",
       "       [1, 0.0, 0.0, 23640.93, 96189.63, 148001.11],\n",
       "       [1, 0.0, 1.0, 15505.73, 127382.3, 35534.17],\n",
       "       [1, 0.0, 0.0, 22177.74, 154806.14, 28334.72],\n",
       "       [1, 0.0, 1.0, 1000.23, 124153.04, 1903.93],\n",
       "       [1, 1.0, 0.0, 1315.46, 115816.21, 297114.46],\n",
       "       [1, 0.0, 0.0, 0.0, 135426.92, 0.0],\n",
       "       [1, 0.0, 1.0, 542.05, 51743.15, 0.0],\n",
       "       [1, 0.0, 0.0, 0.0, 116983.8, 45173.06]], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35aab9c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.6534920e+05,\n",
       "        1.3689780e+05, 4.7178410e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.6259770e+05,\n",
       "        1.5137759e+05, 4.4389853e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.5344151e+05,\n",
       "        1.0114555e+05, 4.0793454e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.4437241e+05,\n",
       "        1.1867185e+05, 3.8319962e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.4210734e+05,\n",
       "        9.1391770e+04, 3.6616842e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.3187690e+05,\n",
       "        9.9814710e+04, 3.6286136e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.3461546e+05,\n",
       "        1.4719887e+05, 1.2771682e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3029813e+05,\n",
       "        1.4553006e+05, 3.2387668e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.2054252e+05,\n",
       "        1.4871895e+05, 3.1161329e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.2333488e+05,\n",
       "        1.0867917e+05, 3.0498162e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.0191308e+05,\n",
       "        1.1059411e+05, 2.2916095e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 1.0067196e+05,\n",
       "        9.1790610e+04, 2.4974455e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.3863750e+04,\n",
       "        1.2732038e+05, 2.4983944e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 9.1992390e+04,\n",
       "        1.3549507e+05, 2.5266493e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.1994324e+05,\n",
       "        1.5654742e+05, 2.5651292e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.1452361e+05,\n",
       "        1.2261684e+05, 2.6177623e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.8013110e+04,\n",
       "        1.2159755e+05, 2.6434606e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 9.4657160e+04,\n",
       "        1.4507758e+05, 2.8257431e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 9.1749160e+04,\n",
       "        1.1417579e+05, 2.9491957e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 8.6419700e+04,\n",
       "        1.5351411e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 7.6253860e+04,\n",
       "        1.1386730e+05, 2.9866447e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.8389470e+04,\n",
       "        1.5377343e+05, 2.9973729e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.3994560e+04,\n",
       "        1.2278275e+05, 3.0331926e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.7532530e+04,\n",
       "        1.0575103e+05, 3.0476873e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.7044010e+04,\n",
       "        9.9281340e+04, 1.4057481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.4664710e+04,\n",
       "        1.3955316e+05, 1.3796262e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 7.5328870e+04,\n",
       "        1.4413598e+05, 1.3405007e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 7.2107600e+04,\n",
       "        1.2786455e+05, 3.5318381e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.6051520e+04,\n",
       "        1.8264556e+05, 1.1814820e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.5605480e+04,\n",
       "        1.5303206e+05, 1.0713838e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 6.1994480e+04,\n",
       "        1.1564128e+05, 9.1131240e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 6.1136380e+04,\n",
       "        1.5270192e+05, 8.8218230e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 6.3408860e+04,\n",
       "        1.2921961e+05, 4.6085250e+04],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 5.5493950e+04,\n",
       "        1.0305749e+05, 2.1463481e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.6426070e+04,\n",
       "        1.5769392e+05, 2.1079767e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 4.6014020e+04,\n",
       "        8.5047440e+04, 2.0551764e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.8663760e+04,\n",
       "        1.2705621e+05, 2.0112682e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 4.4069950e+04,\n",
       "        5.1283140e+04, 1.9702942e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 2.0229590e+04,\n",
       "        6.5947930e+04, 1.8526510e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 3.8558510e+04,\n",
       "        8.2982090e+04, 1.7499930e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.8754330e+04,\n",
       "        1.1854605e+05, 1.7279567e+05],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 2.7892920e+04,\n",
       "        8.4710770e+04, 1.6447071e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.3640930e+04,\n",
       "        9.6189630e+04, 1.4800111e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.5505730e+04,\n",
       "        1.2738230e+05, 3.5534170e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 2.2177740e+04,\n",
       "        1.5480614e+05, 2.8334720e+04],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 1.0002300e+03,\n",
       "        1.2415304e+05, 1.9039300e+03],\n",
       "       [1.0000000e+00, 1.0000000e+00, 0.0000000e+00, 1.3154600e+03,\n",
       "        1.1581621e+05, 2.9711446e+05],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.3542692e+05, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 1.0000000e+00, 5.4205000e+02,\n",
       "        5.1743150e+04, 0.0000000e+00],\n",
       "       [1.0000000e+00, 0.0000000e+00, 0.0000000e+00, 0.0000000e+00,\n",
       "        1.1698380e+05, 4.5173060e+04]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8159014",
   "metadata": {},
   "source": [
    "<h4>Step 2:</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6b6f19",
   "metadata": {},
   "source": [
    "Now, we are actually going to apply a backward elimination process. \n",
    "\n",
    "1. Choose a Significance Level: Define a significance level (e.g., 0.05) to stay in the model. This value is often denoted as SL.\n",
    "\n",
    "\n",
    "2.  Fit the Initial Model: Fit the model with all the possible predictors included.\n",
    "\n",
    "\n",
    "3. Consider the Predictor with the Highest P-value: Identify the predictor with the highest p-value. If the p-value is greater than your chosen significance level (SL), go to the next step. Otherwise, go to step 6.\n",
    "\n",
    "\n",
    "4. Remove the Predictor: Remove the predictor identified in step 3.\n",
    "\n",
    "\n",
    "5. Fit the Model Again: Fit the model without the removed predictor and go back to step 3.\n",
    "\n",
    "\n",
    "6. Finalize the Model: Once you have a model where all predictors have a p-value below the chosen significance level, your model is ready. Otherwise, if you reach a point where all predictors have p-values less than SL, you can finalize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c523cea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
